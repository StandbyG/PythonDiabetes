# -*- coding: utf-8 -*-
"""Proyecto Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OKiQQZSpgFDNApL5_gXyRd0PbYp9XKPm
"""

# Librerías esenciales
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display

# Preprocesamiento y modelado
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Guardado del modelo
import joblib

# Estilo visual
sns.set(style="whitegrid")
#2.1 Cargar los datos
import pandas as pd

# Cargar dataset
df = pd.read_csv('diabetes_dataset.csv')
df.columns = df.columns.str.strip()

# Vista general
print(df.shape)
df.head()

# Copia del DataFrame original
df_original = df.copy()

# Mostrar tipos de datos y valores nulos
print("TIPOS DE DATOS Y NULOS:")
display(df_original.dtypes)
display(df_original.isnull().sum())

# Eliminar columna 'Unnamed: 0' si existe
if 'Unnamed: 0' in df_original.columns:
    df_original.drop(columns=['Unnamed: 0'], inplace=True)

# Estadísticas descriptivas antes de limpiar
print("\nDESCRIPCIÓN ANTES DE LIMPIAR:")
display(df_original.describe())

# Ver cuántas filas serían eliminadas si hacemos dropna
print(f"\nFilas con al menos un valor nulo: {df_original.isnull().any(axis=1).sum()} de {len(df_original)}")

# Recomendación: usar imputación en vez de eliminar, pero si decides continuar:
dataset_cleaned = df_original.dropna().copy()

# Mostrar info post limpieza
print("\nINFO POST LIMPIEZA:")
dataset_cleaned.info()

# Descripción después de limpiar
print("\nDESCRIPCIÓN POST LIMPIEZA:")
display(dataset_cleaned.describe())

# Seleccionamos solo las columnas numéricas
df_numeric = df.select_dtypes(include=['int64', 'float64'])

# Matriz de correlación
plt.figure(figsize=(12,8))
sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Matriz de Correlación entre variables numéricas")
plt.show()

# Generar variable objetivo: Diabetes_Risk
# Umbral clínico de HbA1c: > 6.5 indica posible diabetes
df['Diabetes_Risk'] = (df['HbA1c'] > 6.5).astype(int)

# Revisar distribución
df['Diabetes_Risk'].value_counts()

#INSIGHT N° 5
# Insight: Promedio del Control Glucémico (HbA1c) segun Grupo de edad y Clasificación de BMI
# Crear grupos categóricos para edad e bmi
dataset_cleaned["Age_Group"] = pd.cut(dataset_cleaned["Age"], bins=[0, 30, 45, 60, 100], labels=["<30", "30-45", "45-60", "60+"])
dataset_cleaned["BMI_Group"] = pd.cut(dataset_cleaned["BMI"], bins=[0, 18.5, 24.9, 29.9, 100], labels=["Bajo", "Normal", "Sobrepeso", "Obesidad"])

# Calcular promedio de HbA1c por combinación de grupos
hba1c_means = dataset_cleaned.groupby(["Age_Group", "BMI_Group"])["HbA1c"].mean().unstack()

# Gráfico de calor de HbA1c promedio
plt.figure(figsize=(10, 6))
sns.heatmap(hba1c_means, annot=True, fmt=".2f", cmap="magma", cbar_kws={'label': 'HbA1c promedio'})
plt.title("Relación entre HbA1c y Grupos de Edad e IMC")
plt.xlabel("Grupo de IMC")
plt.ylabel("Grupo de Edad")
plt.tight_layout()
plt.show()

# Separar las variables categóricas y numéricas
categorical_vars = dataset_cleaned.select_dtypes(include='object').columns
numerical_vars = dataset_cleaned.select_dtypes(include=['int64', 'float64']).columns

# Crear los dataframes para variables categóricas y numéricas
categorical_df = dataset_cleaned[categorical_vars]
numerical_df = dataset_cleaned[numerical_vars]


# Mostrar el dataframe de variables categóricas
categorical_df.head(), numerical_df.head()

#INSIGHT N° 1
import matplotlib.pyplot as plt
import seaborn as sns

# Calcular correlaciones
correlation_bmi_glucose = dataset_cleaned['BMI'].corr(df['Fasting_Blood_Glucose'])
correlation_bmi_hba1c = dataset_cleaned['BMI'].corr(df['HbA1c'])

# Crear gráficos de dispersión con líneas de tendencia
plt.figure(figsize=(14, 6))

# BMI vs Fasting Blood Glucose
plt.subplot(1, 2, 1)
sns.regplot(x='BMI', y='Fasting_Blood_Glucose', data=dataset_cleaned, scatter_kws={"alpha":0.5})
plt.title(f'BMI vs Glucosa en Ayunas (r = {correlation_bmi_glucose:.2f})')
plt.xlabel('Índice de Masa Corporal (BMI)')
plt.ylabel('Glucosa en Ayunas (mg/dL)')

# BMI vs HbA1c
plt.subplot(1, 2, 2)
sns.regplot(x='BMI', y='HbA1c', data=dataset_cleaned, scatter_kws={"alpha":0.5})
plt.title(f'BMI vs HbA1c (r = {correlation_bmi_hba1c:.2f})')
plt.xlabel('Índice de Masa Corporal (BMI)')
plt.ylabel('HbA1c (%)')

plt.tight_layout()
plt.show()

#INSIGHT N° 2
import seaborn as sns
import matplotlib.pyplot as plt

# Verificar los valores únicos en las variables de estilo de vida
activity_levels = dataset_cleaned['Physical_Activity_Level'].unique()
alcohol_levels = dataset_cleaned['Alcohol_Consumption'].unique()

activity_levels, alcohol_levels
# Ajustar estilo visual
sns.set(style="whitegrid")

# Crear figura para comparar niveles de HbA1c y Glucosa según estilo de vida
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Actividad física vs HbA1c
sns.boxplot(x='Physical_Activity_Level', y='HbA1c', data=dataset_cleaned, ax=axes[0, 0])
axes[0, 0].set_title('HbA1c según Nivel de Actividad Física')
axes[0, 0].set_xlabel('Nivel de Actividad Física')
axes[0, 0].set_ylabel('HbA1c (%)')

# Actividad física vs Glucosa en ayunas
sns.boxplot(x='Physical_Activity_Level', y='Fasting_Blood_Glucose', data=dataset_cleaned, ax=axes[0, 1])
axes[0, 1].set_title('Glucosa en Ayunas según Nivel de Actividad Física')
axes[0, 1].set_xlabel('Nivel de Actividad Física')
axes[0, 1].set_ylabel('Glucosa en Ayunas (mg/dL)')

# Consumo de alcohol vs HbA1c
sns.boxplot(x='Alcohol_Consumption', y='HbA1c', data=dataset_cleaned, ax=axes[1, 0])
axes[1, 0].set_title('HbA1c según Consumo de Alcohol')
axes[1, 0].set_xlabel('Consumo de Alcohol')
axes[1, 0].set_ylabel('HbA1c (%)')

# Consumo de alcohol vs Glucosa en ayunas
sns.boxplot(x='Alcohol_Consumption', y='Fasting_Blood_Glucose', data=dataset_cleaned, ax=axes[1, 1])
axes[1, 1].set_title('Glucosa en Ayunas según Consumo de Alcohol')
axes[1, 1].set_xlabel('Consumo de Alcohol')
axes[1, 1].set_ylabel('Glucosa en Ayunas (mg/dL)')

plt.tight_layout()
plt.show()

#INSIGHT N° 3
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np


# Variables de salud
health_vars = ['Fasting_Blood_Glucose', 'HbA1c', 'BMI']
sns.set(style='whitegrid')
plt.rcParams['figure.figsize'] = (16, 5)

# 1. Comparación por SEXO
for var in health_vars:
    sns.barplot(data=df, x='Sex', y=var, hue='Sex',
                estimator=np.mean, errorbar='sd', palette='Set2', legend=False)
    plt.title(f'{var} por Sexo')
    plt.ylabel('Media ± SD')
    plt.xlabel('')
    plt.show()

# 2. Comparación por ETNIA
for var in health_vars:
    sns.barplot(data=df, x='Ethnicity', y=var, hue='Ethnicity',
                estimator=np.mean, errorbar='sd', palette='Set3', legend=False)
    plt.title(f'{var} por Etnia')
    plt.ylabel('Media ± SD')
    plt.xlabel('')
    plt.xticks(rotation=45)
    plt.show()

# 3. Comparación por Antecedentes Familiares
for var in health_vars:
    sns.barplot(data=df, x='Family_History_of_Diabetes', y=var,
                hue='Family_History_of_Diabetes',
                estimator=np.mean, errorbar='sd', palette='coolwarm', legend=False)
    plt.title(f'{var} por Antecedentes Familiares de Diabetes')
    plt.ylabel('Media ± SD')
    plt.xlabel('Antecedentes Familiares (0 = No, 1 = Sí)')
    plt.show()

#INSIGHT N° 4
import matplotlib.pyplot as plt
import seaborn as sns

# Crear el gráfico

plt.figure(figsize=(15, 5))

# Obtener los niveles únicos de consumo de alcohol
alcohol_levels = dataset_cleaned['Alcohol_Consumption'].unique()

# Generar un histograma para cada nivel
for i, level in enumerate(alcohol_levels, 1):
    subset = dataset_cleaned[dataset_cleaned['Alcohol_Consumption'] == level]
    plt.subplot(1, len(alcohol_levels), i)
    sns.histplot(subset['HbA1c'], kde=True, bins=30, color='gold')
    plt.title(f'HbA1c - Consumo de alcohol: {level}')
    plt.xlabel('HbA1c (%)')
    plt.ylabel('Cantidad de personas')
    plt.grid(True)

plt.tight_layout()
plt.show()

# Calcular los promedios de HbA1c por grupo de alcohol
dataset_cleaned.groupby('Alcohol_Consumption')['HbA1c'].mean()

#ESTO SOLO ES PARA PROBAR ALGUNAS COSAS
import matplotlib.pyplot as plt
import seaborn as sns

# Ajustar el número de subgráficas para adaptarse a más de 9 variables numéricas
plt.figure(figsize=(15, 12))
num_vars_count = len(numerical_vars)

# Graficar las distribuciones de las variables numéricas en un número adecuado de subgráficas
for i, var in enumerate(numerical_vars, 1):
    plt.subplot(num_vars_count // 3 + 1, 3, i)
    sns.histplot(dataset_cleaned[var], kde=True)
    plt.title(f'Distribución de {var}')
    plt.tight_layout()
    # Insight específico: analizar la forma de la distribución
    if var == 'BMI':
        print("Insight sobre BMI: Distribución sesgada hacia la derecha.")
    elif var == 'Fasting_Blood_Glucose':
        print("Insight sobre Glucosa: Presencia de picos, lo que indica valores típicos más altos.")
plt.show()

# 2. Repetir las distribuciones de las variables categóricas
plt.figure(figsize=(15, 8))
for i, var in enumerate(categorical_vars, 1):
    plt.subplot(2, 3, i)
    sns.countplot(data=dataset_cleaned, x=var)
    plt.title(f'Distribución de {var}')
    plt.tight_layout()
    # Insight específico: analizar la distribución de categorías
    if var == 'Sex':
        print("Insight sobre Sexo: Distribución equilibrada entre masculino y femenino.")
    elif var == 'Alcohol_Consumption':
        print("Insight sobre Consumo de Alcohol: Mayor prevalencia de consumo moderado.")
plt.show()

# 3. Correlación entre variables numéricas
correlation_matrix = dataset_cleaned[numerical_vars].corr()

# Visualizar la matriz de correlación
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Matriz de Correlación entre Variables Numéricas')
plt.tight_layout()
plt.show()

# 4. Estadísticas descriptivas
descriptive_stats = dataset_cleaned.describe()

print(descriptive_stats)
# Insight específico: resaltar estadísticas clave de las variables
print("Insight sobre Edad: La edad promedio de la muestra es 44.62, indicando una población relativamente madura.")
if descriptive_stats['BMI']['mean'] > 30:
    print("Insight sobre BMI: El BMI promedio es alto, lo que indica una posible prevalencia de sobrepeso u obesidad.")

# Separar variables
X = df.drop(columns=['HbA1c', 'Diabetes_Risk'])  # quitar objetivo y variable umbral
y = df['Diabetes_Risk']

# Detectar tipos de columnas
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X.select_dtypes(include='object').columns.tolist()

# Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42)

# Pipelines
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Definimos los modelos y sus hiperparámetros
models_params = {
    'Logistic Regression': {
        'model': LogisticRegression(max_iter=1000),
        'params': {
            'classifier__C': [0.01, 0.1, 1, 10]
        }
    },
    'Random Forest': {
        'model': RandomForestClassifier(),
        'params': {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [None, 5, 10]
        }
    },
    'XGBoost': {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
        'params': {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [3, 5],
            'classifier__learning_rate': [0.05, 0.1]
        }
}
    }

# Donde guardaremos los resultados
best_models = {}

# GridSearch para cada modelo
for model_name, mp in models_params.items():
    print(f"\n🔍 Optimizando modelo: {model_name}")

    pipe = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', mp['model'])
    ])

    grid = GridSearchCV(pipe, mp['params'], cv=5, scoring='roc_auc', n_jobs=-1)
    grid.fit(X_train, y_train)

    best_models[model_name] = {
        'model': grid.best_estimator_,
        'score': grid.best_score_,
        'params': grid.best_params_
    }

    print(f"✅ Mejor AUC: {grid.best_score_:.4f}")
    print(f"📌 Mejores parámetros: {grid.best_params_}")

# Escoger el mejor modelo del diccionario de resultados
best_model_name, best_model_info = max(best_models.items(), key=lambda x: x[1]['score'])
best_model = best_model_info['model']

print(f"🏆 Mejor modelo: {best_model_name}")

# Hacer predicciones
y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)[:, 1]

# Reporte de desempeño
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

print("📊 Classification Report:\n", classification_report(y_test, y_pred))
print(f"🔵 ROC AUC: {roc_auc_score(y_test, y_proba):.4f}")

# Matriz de confusión
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title(f"Matriz de Confusión - {best_model_name}")
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.show()

import joblib

joblib.dump(best_model, f"/content/drive/MyDrive/ProyectoFinalBPA/{best_model_name.replace(' ', '_')}_diabetes_model.pkl")
print("Modelo guardado exitosamente.")
